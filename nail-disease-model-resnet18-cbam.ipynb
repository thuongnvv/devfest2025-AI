{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":9292141,"sourceType":"datasetVersion","datasetId":5625424},{"sourceId":6880434,"sourceType":"datasetVersion","datasetId":3953194}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, Dataset\nfrom PIL import Image\nimport os\nimport random\nimport glob\nimport copy\nimport time\n\n# ==========================================\n# 1. CẤU HÌNH & THAM SỐ\n# ==========================================\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Đang sử dụng thiết bị: {device}\")\n\n# Đường dẫn gốc chứa folder 'train' và 'validation'\nDATA_DIR = '/kaggle/input/nail-disease-detection-dataset/data' \n\n# Đường dẫn folder chứa ảnh nhiễu/unknown (Folder \"a\")\nUNKNOWN_DIR = '/kaggle/input/vehicle-classification/test'  # Thay bằng đường dẫn thật của bạn\n\nBATCH_SIZE = 32\nNUM_EPOCHS = 15\nLEARNING_RATE = 0.0005\nMAX_IMAGES_PER_CLASS = 800  # Chỉ áp dụng cho tập Train\n\n# ==========================================\n# 2. ĐỊNH NGHĨA AUGMENTATION\n# ==========================================\n\n# Transform cơ bản (cho Val/Test)\nbase_transform = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Augmentation nhẹ cho các lớp bệnh móng tay (giữ cấu trúc móng)\nnormal_aug = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10), # Xoay ít hơn vì hướng móng tay quan trọng\n    transforms.ColorJitter(brightness=0.1, contrast=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# Augmentation CỰC MẠNH cho lớp Unknown\nstrong_aug = transforms.Compose([\n    transforms.Resize((224, 224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomVerticalFlip(),\n    transforms.RandomAffine(degrees=180, translate=(0.2, 0.2), shear=20, scale=(0.5, 1.5)),\n    transforms.RandomPerspective(distortion_scale=0.5, p=0.5),\n    transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.2),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n])\n\n# ==========================================\n# 3. CUSTOM DATASET (XỬ LÝ LOGIC)\n# ==========================================\nclass BalancedNailDataset(Dataset):\n    def __init__(self, root_dir, unknown_dir=None, max_per_class=800, is_train=True):\n        self.data = [] \n        # Lấy danh sách lớp từ thư mục hiện tại (train hoặc val)\n        self.classes = sorted([d for d in os.listdir(root_dir) if os.path.isdir(os.path.join(root_dir, d))])\n        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n        \n        self.is_train = is_train\n        \n        # Nếu là tập Train, ta thêm lớp Unknown vào danh sách quản lý\n        if self.is_train and unknown_dir:\n            self.classes.append(\"Unknown\")\n            self.unknown_label = len(self.classes) - 1\n        else:\n            self.unknown_label = -1 # Không có unknown trong validation (hoặc xử lý sau)\n\n        # --- LOAD ẢNH TỪ CÁC LỚP BỆNH ---\n        for cls_name in os.listdir(root_dir):\n            cls_folder = os.path.join(root_dir, cls_name)\n            if not os.path.isdir(cls_folder): continue\n            \n            images = glob.glob(os.path.join(cls_folder, \"*.*\"))\n            images = [f for f in images if f.lower().endswith(('.png', '.jpg', '.jpeg', '.bmp'))]\n            \n            # LOGIC: Chỉ cân bằng số lượng ở tập Train\n            if self.is_train and len(images) > max_per_class:\n                selected_images = random.sample(images, max_per_class)\n            else:\n                selected_images = images # Val lấy hết, hoặc Train ít hơn 300 thì lấy hết\n            \n            label = self.class_to_idx[cls_name]\n            for img_path in selected_images:\n                self.data.append((img_path, label))\n\n        # --- LOAD ẢNH UNKNOWN (CHỈ CHO TRAIN) ---\n        if self.is_train and unknown_dir and os.path.exists(unknown_dir):\n            unknown_images = glob.glob(os.path.join(unknown_dir, \"*.*\"))\n            unknown_images = [f for f in unknown_images if f.lower().endswith(('.png', '.jpg', '.jpeg'))]\n            \n            # Cân bằng lớp Unknown\n            if len(unknown_images) > max_per_class:\n                selected_unknown = random.sample(unknown_images, max_per_class)\n            else:\n                selected_unknown = unknown_images\n\n            for img_path in selected_unknown:\n                self.data.append((img_path, self.unknown_label))\n            \n            print(f\"[TRAIN] Đã thêm Unknown. Tổng ảnh Train: {len(self.data)}\")\n        elif not self.is_train:\n            print(f\"[VAL] Load validation set. Tổng ảnh Val: {len(self.data)}\")\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_path, label = self.data[idx]\n        try:\n            image = Image.open(img_path).convert('RGB')\n        except:\n            image = Image.new('RGB', (224, 224))\n\n        # Logic Augmentation\n        if not self.is_train:\n            # Validation -> Base Transform\n            image = base_transform(image)\n        else:\n            # Train -> Check Unknown\n            if label == self.unknown_label:\n                image = strong_aug(image)\n            else:\n                image = normal_aug(image)\n\n        return image, label\nclass ChannelAttention(nn.Module):\n    def __init__(self, in_planes, ratio=16):\n        super(ChannelAttention, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.max_pool = nn.AdaptiveMaxPool2d(1)\n        \n        # Lưu ý: ResNet18 channel nhỏ, nếu in_planes < 16 thì ratio=16 sẽ lỗi\n        # Ta điều chỉnh ratio an toàn\n        safe_ratio = ratio if in_planes >= ratio else 1\n        \n        self.fc1 = nn.Conv2d(in_planes, in_planes // safe_ratio, 1, bias=False)\n        self.relu1 = nn.ReLU()\n        self.fc2 = nn.Conv2d(in_planes // safe_ratio, in_planes, 1, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = self.fc2(self.relu1(self.fc1(self.avg_pool(x))))\n        max_out = self.fc2(self.relu1(self.fc1(self.max_pool(x))))\n        return self.sigmoid(avg_out + max_out)\n\nclass SpatialAttention(nn.Module):\n    def __init__(self, kernel_size=7):\n        super(SpatialAttention, self).__init__()\n        self.conv1 = nn.Conv2d(2, 1, kernel_size, padding=kernel_size//2, bias=False)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        avg_out = torch.mean(x, dim=1, keepdim=True)\n        max_out, _ = torch.max(x, dim=1, keepdim=True)\n        x = torch.cat([avg_out, max_out], dim=1)\n        return self.sigmoid(self.conv1(x))\n\nclass CBAM(nn.Module):\n    def __init__(self, in_planes, ratio=16, kernel_size=7):\n        super(CBAM, self).__init__()\n        self.ca = ChannelAttention(in_planes, ratio)\n        self.sa = SpatialAttention(kernel_size)\n\n    def forward(self, x):\n        out = x * self.ca(x)\n        out = out * self.sa(out)\n        return out\n\n# ==========================================\n# 2. CBAM TÍCH HỢP VÀO RESNET18\n# ==========================================\nclass CBAMResNet18(nn.Module):\n    def __init__(self, num_classes):\n        super(CBAMResNet18, self).__init__()\n        # Load ResNet18 pretrained\n        self.backbone = models.resnet18(weights=models.ResNet18_Weights.DEFAULT)\n        \n        # --- CẤU HÌNH KÊNH CỦA RESNET18 ---\n        # Layer 1: 64 channels\n        # Layer 2: 128 channels\n        # Layer 3: 256 channels\n        # Layer 4: 512 channels (Nhỏ hơn nhiều so với 2048 của ResNet50)\n        \n        self.cbam1 = CBAM(64)\n        self.cbam2 = CBAM(128)\n        self.cbam3 = CBAM(256)\n        self.cbam4 = CBAM(512)\n        \n        # Classifier\n        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n        # Input của FC layer cuối cùng là 512\n        self.fc = nn.Linear(512, num_classes)\n\n    def forward(self, x):\n        # Phần đầu (Stem)\n        x = self.backbone.conv1(x)\n        x = self.backbone.bn1(x)\n        x = self.backbone.relu(x)\n        x = self.backbone.maxpool(x)\n\n        # Layer 1 + CBAM\n        x = self.backbone.layer1(x)\n        x = self.cbam1(x)\n\n        # Layer 2 + CBAM\n        x = self.backbone.layer2(x)\n        x = self.cbam2(x)\n\n        # Layer 3 + CBAM\n        x = self.backbone.layer3(x)\n        x = self.cbam3(x)\n\n        # Layer 4 + CBAM\n        x = self.backbone.layer4(x)\n        x = self.cbam4(x)\n\n        # Head\n        x = self.avgpool(x)\n        x = torch.flatten(x, 1)\n        x = self.fc(x)\n        return x\n\n# ==========================================\n# 5. CHUẨN BỊ DATA LOADERS\n# ==========================================\ntrain_dir = os.path.join(DATA_DIR, 'train')\nval_dir = os.path.join(DATA_DIR, 'validation')\n\n# Dataset Train: Có cân bằng, Có Unknown, Có Augmentation mạnh\ntrain_dataset = BalancedNailDataset(train_dir, UNKNOWN_DIR, max_per_class=MAX_IMAGES_PER_CLASS, is_train=True)\n\n# Dataset Val: Giữ nguyên, không thêm Unknown (trừ khi folder Val có sẵn), không giới hạn\nval_dataset = BalancedNailDataset(val_dir, unknown_dir=None, max_per_class=9999, is_train=False)\n\ndataloaders = {\n    'train': DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=2),\n    'validation': DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=2)\n}\ndataset_sizes = {'train': len(train_dataset), 'validation': len(val_dataset)}\n\n# Cập nhật số lượng lớp thực tế (bao gồm Unknown nếu có)\nclass_names = train_dataset.classes\nNUM_CLASSES = len(class_names)\nprint(f\"Final Classes: {class_names} (Total: {NUM_CLASSES})\")\n\n# ==========================================\n# 6. TRAINING LOOP\n# ==========================================\nmodel = CBAMResNet18(num_classes=NUM_CLASSES)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n\ndef train_model(model, criterion, optimizer, num_epochs=10):\n    since = time.time()\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print(f'Epoch {epoch+1}/{num_epochs}')\n        print('-' * 10)\n\n        for phase in ['train', 'validation']:\n            if phase == 'train':\n                model.train()\n            else:\n                model.eval()\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            for inputs, labels in dataloaders[phase]:\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n\n                optimizer.zero_grad()\n\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n\n            if phase == 'validation' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n                torch.save(model.state_dict(), 'resnet18_cbam_nail_best.pth')\n                print(f\"--> New Best Model! Acc: {best_acc:.4f}\")\n\n        print()\n\n    time_elapsed = time.time() - since\n    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n    print(f'Best Val Acc: {best_acc:.4f}')\n    model.load_state_dict(best_model_wts)\n    return model\n\nif __name__ == '__main__':\n    # Kiểm tra folder Unknown trước khi chạy\n    if not os.path.exists(UNKNOWN_DIR):\n        print(f\"WARNING: Không tìm thấy {UNKNOWN_DIR}. Model sẽ train mà không có lớp Unknown!\")\n    \n    model_ft = train_model(model, criterion, optimizer, num_epochs=NUM_EPOCHS)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-22T06:46:55.780665Z","iopub.execute_input":"2025-11-22T06:46:55.780911Z","iopub.status.idle":"2025-11-22T06:51:35.790891Z","shell.execute_reply.started":"2025-11-22T06:46:55.780891Z","shell.execute_reply":"2025-11-22T06:51:35.790055Z"}},"outputs":[{"name":"stdout","text":"Đang sử dụng thiết bị: cuda\n[TRAIN] Đã thêm Unknown. Tổng ảnh Train: 3944\n[VAL] Load validation set. Tổng ảnh Val: 91\nFinal Classes: ['Acral_Lentiginous_Melanoma', 'Healthy_Nail', 'Onychogryphosis', 'blue_finger', 'clubbing', 'pitting', 'Unknown'] (Total: 7)\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 188MB/s]\n","output_type":"stream"},{"name":"stdout","text":"Epoch 1/15\n----------\ntrain Loss: 0.6426 Acc: 0.7766\nvalidation Loss: 0.8699 Acc: 0.7143\n--> New Best Model! Acc: 0.7143\n\nEpoch 2/15\n----------\ntrain Loss: 0.3849 Acc: 0.8689\nvalidation Loss: 0.2722 Acc: 0.8901\n--> New Best Model! Acc: 0.8901\n\nEpoch 3/15\n----------\ntrain Loss: 0.3131 Acc: 0.8895\nvalidation Loss: 0.1937 Acc: 0.9121\n--> New Best Model! Acc: 0.9121\n\nEpoch 4/15\n----------\ntrain Loss: 0.2546 Acc: 0.9105\nvalidation Loss: 0.4066 Acc: 0.8242\n\nEpoch 5/15\n----------\ntrain Loss: 0.2281 Acc: 0.9217\nvalidation Loss: 0.3015 Acc: 0.8901\n\nEpoch 6/15\n----------\ntrain Loss: 0.1802 Acc: 0.9338\nvalidation Loss: 0.3480 Acc: 0.8901\n\nEpoch 7/15\n----------\ntrain Loss: 0.1871 Acc: 0.9366\nvalidation Loss: 0.4169 Acc: 0.8791\n\nEpoch 8/15\n----------\ntrain Loss: 0.1141 Acc: 0.9602\nvalidation Loss: 0.5315 Acc: 0.8681\n\nEpoch 9/15\n----------\ntrain Loss: 0.1620 Acc: 0.9462\nvalidation Loss: 0.1713 Acc: 0.9341\n--> New Best Model! Acc: 0.9341\n\nEpoch 10/15\n----------\ntrain Loss: 0.1401 Acc: 0.9473\nvalidation Loss: 0.4595 Acc: 0.8681\n\nEpoch 11/15\n----------\ntrain Loss: 0.1101 Acc: 0.9610\nvalidation Loss: 0.4622 Acc: 0.8571\n\nEpoch 12/15\n----------\ntrain Loss: 0.0996 Acc: 0.9686\nvalidation Loss: 0.3854 Acc: 0.8681\n\nEpoch 13/15\n----------\ntrain Loss: 0.0867 Acc: 0.9696\nvalidation Loss: 0.5133 Acc: 0.8462\n\nEpoch 14/15\n----------\ntrain Loss: 0.0949 Acc: 0.9688\nvalidation Loss: 0.5452 Acc: 0.8571\n\nEpoch 15/15\n----------\ntrain Loss: 0.0993 Acc: 0.9630\nvalidation Loss: 0.5515 Acc: 0.8352\n\nTraining complete in 4m 31s\nBest Val Acc: 0.9341\n","output_type":"stream"}],"execution_count":1}]}