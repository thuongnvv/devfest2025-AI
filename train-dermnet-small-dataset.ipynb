{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":1276317,"sourceType":"datasetVersion","datasetId":735911}],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nfrom typing import List, Dict\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader\nfrom torchvision import datasets, transforms, models\nfrom PIL import Image\nimport timm  # pip install timm n·∫øu ch∆∞a c√≥\n\n\n# ============= CONFIG =============\nDEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\nDATA_ROOT = \"/kaggle/input/dermnet\"   # s·ª≠a path cho ƒë√∫ng\nBATCH_SIZE = 32\nIMAGE_SIZE = 224\nEPOCHS = 5\nBEST_MODEL_PATH = \"best_medagen_resnet18_vits_cbam.pth\"\n\nSELECTED_CLASSES: List[str] = [\n    \"Acne and Rosacea Photos\",\n    \"Actinic Keratosis Basal Cell Carcinoma and other Malignant Lesions\",\n    \"Atopic Dermatitis Photos\",\n    \"Cellulitis Impetigo and other Bacterial Infections\",\n    \"Eczema Photos\",\n    \"Hair Loss Photos Alopecia and other Hair Diseases\",\n    \"Melanoma Skin Cancer Nevi and Moles\",\n    \"Nail Fungus and other Nail Disease\",\n    \"Poison Ivy Photos and other Contact Dermatitis\",\n    \"Psoriasis pictures Lichen Planus and related diseases\",\n    \"Scabies Lyme Disease and other Infestations and Bites\",\n    \"Seborrheic Keratoses and other Benign Tumors\",\n    \"Tinea Ringworm Candidiasis and other Fungal Infections\",\n    \"Warts Molluscum and other Viral Infections\",\n]\n\n\n# ============= TRANSFORMS =============\ntrain_tfms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(8),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\ntest_tfms = transforms.Compose([\n    transforms.Resize((IMAGE_SIZE, IMAGE_SIZE)),\n    transforms.ToTensor(),\n    transforms.Normalize([0.485, 0.456, 0.406],\n                         [0.229, 0.224, 0.225]),\n])\n\n\ndef load_filtered_dataset(split: str, transform):\n    root = os.path.join(DATA_ROOT, split)\n    ds = datasets.ImageFolder(root=root, transform=transform)\n\n    orig_class_to_idx = ds.class_to_idx\n\n    for cls in SELECTED_CLASSES:\n        if cls not in orig_class_to_idx:\n            raise ValueError(f\"Kh√¥ng t√¨m th·∫•y class: {cls} trong {root}\")\n\n    allowed = {orig_class_to_idx[c] for c in SELECTED_CLASSES}\n    orig_to_new = {orig_class_to_idx[c]: i for i, c in enumerate(SELECTED_CLASSES)}\n\n    filtered_samples = []\n    for path, target in ds.samples:\n        if target in allowed:\n            filtered_samples.append((path, orig_to_new[target]))\n\n    ds.samples = filtered_samples\n    ds.targets = [t for _, t in filtered_samples]\n    ds.classes = SELECTED_CLASSES\n    ds.class_to_idx = {cls: i for i, cls in enumerate(SELECTED_CLASSES)}\n    return ds\n\n\n# ============= CBAM MODULE =============\nclass CBAM(nn.Module):\n    def __init__(self, channels: int, reduction: int = 16, spatial_kernel: int = 7):\n        super().__init__()\n        # Channel attention\n        self.mlp = nn.Sequential(\n            nn.Linear(channels, channels // reduction, bias=False),\n            nn.ReLU(inplace=True),\n            nn.Linear(channels // reduction, channels, bias=False),\n        )\n        # Spatial attention\n        self.spatial = nn.Conv2d(2, 1, kernel_size=spatial_kernel,\n                                 padding=spatial_kernel // 2, bias=False)\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        b, c, h, w = x.size()\n\n        # ----- Channel attention -----\n        avg_pool = F.adaptive_avg_pool2d(x, 1).view(b, c)\n        max_pool = F.adaptive_max_pool2d(x, 1).view(b, c)\n        ch_att = torch.sigmoid(self.mlp(avg_pool) + self.mlp(max_pool)).view(b, c, 1, 1)\n        x = x * ch_att\n\n        # ----- Spatial attention -----\n        avg = torch.mean(x, dim=1, keepdim=True)\n        mx, _ = torch.max(x, dim=1, keepdim=True)\n        s = torch.cat([avg, mx], dim=1)   # [B, 2, H, W]\n        sp_att = torch.sigmoid(self.spatial(s))\n        x = x * sp_att\n        return x\n\n\n# ============= FUSION MODEL =============\nclass ResNet18_ViTS_CBAM(nn.Module):\n    def __init__(self, num_classes: int):\n        super().__init__()\n\n        # ResNet18 backbone (feature map 512-d)\n        rn = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n        self.resnet_backbone = nn.Sequential(*list(rn.children())[:-1])  # [B,512,1,1]\n        res_dim = 512\n\n        # ViT small patch16 224 (timm)\n        self.vit = timm.create_model(\"vit_small_patch16_224\", pretrained=True)\n        vit_dim = self.vit.embed_dim\n        # b·ªè head, ch·ªâ l·∫•y embedding\n        if hasattr(self.vit, \"head\"):\n            self.vit.reset_classifier(0)\n\n        fused_dim = res_dim + vit_dim\n        self.cbam = CBAM(fused_dim, reduction=16, spatial_kernel=3)\n        self.classifier = nn.Sequential(\n            nn.Linear(fused_dim, 512),\n            nn.ReLU(inplace=True),\n            nn.Dropout(0.3),\n            nn.Linear(512, num_classes),\n        )\n\n    def forward(self, x: torch.Tensor) -> torch.Tensor:\n        # ResNet branch\n        r = self.resnet_backbone(x)              # [B,512,1,1]\n        r = r.view(r.size(0), -1)                # [B,512]\n\n        # ViT branch\n        v = self.vit(x)                          # [B,vit_dim]\n\n        feat = torch.cat([r, v], dim=1)          # [B, C]\n        feat_4d = feat.unsqueeze(-1).unsqueeze(-1)  # [B,C,1,1]\n        feat_4d = self.cbam(feat_4d)             # CBAM attention\n        feat = feat_4d.view(feat_4d.size(0), -1)\n        out = self.classifier(feat)\n        return out\n\n\n# ============= LOAD DATA =============\ntrain_dataset = load_filtered_dataset(\"train\", train_tfms)\ntest_dataset  = load_filtered_dataset(\"test\",  test_tfms)\n\ntrain_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True,  num_workers=4)\ntest_loader  = DataLoader(test_dataset,  batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n\nprint(\"S·ªë l·ªõp:\", len(SELECTED_CLASSES))\nprint(\"S·ªë ·∫£nh train:\", len(train_dataset), \"| S·ªë ·∫£nh test:\", len(test_dataset))\n\n\n# ============= INIT MODEL =============\nnum_classes = len(SELECTED_CLASSES)\nmodel = ResNet18_ViTS_CBAM(num_classes=num_classes).to(DEVICE)\nprint('params:', sum(p.numel() for p in model.parameters()))\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\nbest_test_acc = 0.0\n\n\n# ============= TRAIN LOOP =============\nfor epoch in range(1, EPOCHS + 1):\n    # ---- Train ----\n    model.train()\n    running_loss, correct, total = 0.0, 0, 0\n    for imgs, labels in train_loader:\n        imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n\n        optimizer.zero_grad()\n        outputs = model(imgs)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item() * imgs.size(0)\n        _, preds = outputs.max(1)\n        correct += preds.eq(labels).sum().item()\n        total += labels.size(0)\n\n    train_loss = running_loss / total\n    train_acc  = correct / total\n\n    # ---- Eval ----\n    model.eval()\n    correct_test, total_test = 0, 0\n    with torch.no_grad():\n        for imgs, labels in test_loader:\n            imgs, labels = imgs.to(DEVICE), labels.to(DEVICE)\n            outputs = model(imgs)\n            _, preds = outputs.max(1)\n            correct_test += preds.eq(labels).sum().item()\n            total_test += labels.size(0)\n\n    test_acc = correct_test / total_test\n\n    print(f\"Epoch {epoch}/{EPOCHS} | \"\n          f\"TrainLoss {train_loss:.4f} | TrainAcc {train_acc:.4f} | TestAcc {test_acc:.4f}\")\n\n    # ---- Save best ----\n    if test_acc > best_test_acc:\n        best_test_acc = test_acc\n        torch.save(\n            {\"model_state\": model.state_dict(), \"classes\": SELECTED_CLASSES},\n            BEST_MODEL_PATH,\n        )\n        print(f\"üî• L∆∞u best model (TestAcc={test_acc:.4f}) ‚Üí {BEST_MODEL_PATH}\")\n\n\n# ============= INFERENCE 1 ·∫¢NH =============\nIMG_PATH = \"example.jpg\"  # s·ª≠a path ·∫£nh ri√™ng ƒë·ªÉ test\n\nif os.path.exists(IMG_PATH) and os.path.isfile(IMG_PATH):\n    ckpt = torch.load(BEST_MODEL_PATH, map_location=DEVICE)\n    model.load_state_dict(ckpt[\"model_state\"])\n    model.eval()\n\n    img = Image.open(IMG_PATH).convert(\"RGB\")\n    img_t = test_tfms(img).unsqueeze(0).to(DEVICE)\n\n    with torch.no_grad():\n        logits = model(img_t)\n        probs = torch.softmax(logits, dim=1)[0]\n        topk = torch.topk(probs, k=3)\n\n    print(f\"\\n=== K·∫øt qu·∫£ inference cho: {IMG_PATH} ===\")\n    for i in range(topk.indices.size(0)):\n        idx = topk.indices[i].item()\n        cls_name = SELECTED_CLASSES[idx]\n        p = float(topk.values[i]) * 100\n        print(f\"{i+1}. {cls_name} ‚Äî {p:.2f}%\")\nelse:\n    print(\"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y IMG_PATH, b·ªè qua inference.\")\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-19T04:11:50.814617Z","iopub.execute_input":"2025-11-19T04:11:50.814787Z","iopub.status.idle":"2025-11-19T04:20:49.589226Z","shell.execute_reply.started":"2025-11-19T04:11:50.814770Z","shell.execute_reply":"2025-11-19T04:20:49.588023Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"S·ªë l·ªõp: 14\nS·ªë ·∫£nh train: 11596 | S·ªë ·∫£nh test: 3007\n","output_type":"stream"},{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 44.7M/44.7M [00:00<00:00, 204MB/s]\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/88.2M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d0d6165e4ed4c2b81372bad257f59c7"}},"metadata":{}},{"name":"stdout","text":"params: 33408992\nEpoch 1/5 | TrainLoss 1.6815 | TrainAcc 0.4588 | TestAcc 0.5647\nüî• L∆∞u best model (TestAcc=0.5647) ‚Üí best_medagen_resnet18_vits_cbam.pth\nEpoch 2/5 | TrainLoss 1.1282 | TrainAcc 0.6319 | TestAcc 0.6498\nüî• L∆∞u best model (TestAcc=0.6498) ‚Üí best_medagen_resnet18_vits_cbam.pth\nEpoch 3/5 | TrainLoss 0.8151 | TrainAcc 0.7352 | TestAcc 0.6698\nüî• L∆∞u best model (TestAcc=0.6698) ‚Üí best_medagen_resnet18_vits_cbam.pth\nEpoch 4/5 | TrainLoss 0.5581 | TrainAcc 0.8126 | TestAcc 0.6874\nüî• L∆∞u best model (TestAcc=0.6874) ‚Üí best_medagen_resnet18_vits_cbam.pth\nEpoch 5/5 | TrainLoss 0.3884 | TrainAcc 0.8696 | TestAcc 0.6997\nüî• L∆∞u best model (TestAcc=0.6997) ‚Üí best_medagen_resnet18_vits_cbam.pth\n‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y IMG_PATH, b·ªè qua inference.\n","output_type":"stream"}],"execution_count":1}]}